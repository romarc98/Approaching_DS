{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e5a030b",
   "metadata": {},
   "source": [
    "<div style=\"padding:16px 18px;border:1px solid rgba(0,0,0,.10);border-radius:16px;background:#ffffff;\">\n",
    "  <div style=\"font-size:28px;font-weight:800;line-height:1.15;\">\n",
    "    Approaching_DS · <span style=\"color:#009BC8;\">Basis: Connecting a free LLM service</span>\n",
    "  </div>\n",
    "  <div style=\"margin-top:6px;color:rgba(0,0,0,.65);\">\n",
    "    Subtítulo: Se muestra una conexión a LLM open - source.\n",
    "  </div>\n",
    "\n",
    "  <div style=\"height:4px;background:#009BC8;border-radius:999px;margin:14px 0 12px 0;\"></div>\n",
    "\n",
    "  <table style=\"width:100%;border-collapse:collapse;\">\n",
    "    <tr>\n",
    "      <td style=\"padding:8px 10px;border:1px solid rgba(0,0,0,.08);border-radius:12px;\">\n",
    "        <b>Autor</b><br><span style=\"color:rgba(0,0,0,.65);\">@romarc98</span>\n",
    "      </td>\n",
    "      <td style=\"padding:8px 10px;border:1px solid rgba(0,0,0,.08);border-radius:12px;\">\n",
    "        <b>Fecha</b><br><span style=\"color:rgba(0,0,0,.65);\">2026-Q1</span>\n",
    "      </td>\n",
    "      <td style=\"padding:8px 10px;border:1px solid rgba(0,0,0,.08);border-radius:12px;\">\n",
    "        <b>Status</b><br><span style=\"color:rgba(0,0,0,.65);\">Draft</span>\n",
    "      </td>\n",
    "    </tr>\n",
    "  </table>\n",
    "  </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22691f5",
   "metadata": {},
   "source": [
    "<div style=\"padding:10px 12px;border-radius:14px;border:1px solid rgba(0,155,200,.35);background:rgba(0,155,200,.10);\">\n",
    "  <b style=\"color:#007FA6;\">Info</b><br>\n",
    "  <span style=\"color:rgba(0,0,0,.70);\">\n",
    "    Experimentación con el Client de Ollama y la capacidad para llamar a sus \"n\" modelos open - source.\n",
    "  \n",
    "  </span>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c46dbe2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, '{\"version\":\"0.13.5\"}')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def check_ollama():\n",
    "    try:\n",
    "        r = requests.get(\"http://localhost:11434/api/version\", timeout=2)\n",
    "        return r.status_code, r.text\n",
    "    except Exception as e:\n",
    "        return None, str(e)\n",
    "\n",
    "check_ollama()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2099430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3.2 | pulling dde5aa3fc5ff | 100.00%  (2,019.4 / 2,019.4 MB)\n",
      "Descarga finalizada.\n"
     ]
    }
   ],
   "source": [
    "import requests, json, time\n",
    "\n",
    "BASE = \"http://127.0.0.1:11434\"\n",
    "\n",
    "def pull_model(model: str, timeout_s: int = 3600):\n",
    "    \"\"\"\n",
    "    Descarga un modelo en Ollama usando la API HTTP.\n",
    "    Muestra progreso aproximado si el servidor lo reporta.\n",
    "    \"\"\"\n",
    "    url = f\"{BASE}/api/pull\"\n",
    "    payload = {\"model\": model, \"stream\": True}\n",
    "\n",
    "    with requests.post(url, json=payload, stream=True, timeout=timeout_s) as r:\n",
    "        r.raise_for_status()\n",
    "\n",
    "        last_print = time.time()\n",
    "        for line in r.iter_lines():\n",
    "            if not line:\n",
    "                continue\n",
    "            msg = json.loads(line.decode(\"utf-8\"))\n",
    "\n",
    "            status = msg.get(\"status\", \"\")\n",
    "            total = msg.get(\"total\", 0)\n",
    "            completed = msg.get(\"completed\", 0)\n",
    "\n",
    "            # Throttle prints\n",
    "            if time.time() - last_print < 0.05:\n",
    "                continue\n",
    "            last_print = time.time()\n",
    "\n",
    "            if total:\n",
    "                pct = (completed / total) * 100\n",
    "                print(f\"{model} | {status:20s} | {pct:6.2f}%  ({completed/1e6:,.1f} / {total/1e6:,.1f} MB)\", end=\"\\r\")\n",
    "            else:\n",
    "                # Mensajes sin barra de progreso\n",
    "                print(f\"{model} | {status:20s} | {msg}\", end=\"\\r\")\n",
    "\n",
    "    print(\"\\nDescarga finalizada.\")\n",
    "\n",
    "# Ejemplo: modelo ligero para empezar\n",
    "pull_model(\"llama3.2\")\n",
    "\n",
    "# pull_model(\"llama3.1:8b\")\n",
    "# pull_model(\"qwen2.5:7b-instruct\")\n",
    "# pull_model(\"mistral:7b-instruct\")\n",
    "# pull_model(\"gemma2:2b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3674e3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET /api/version -> 200 | application/json; charset=utf-8\n",
      "{\"version\":\"0.13.5\"}\n",
      "--------------------------------------------------------------------------------\n",
      "GET /api/tags -> 200 | application/json; charset=utf-8\n",
      "{\"models\":[{\"name\":\"llama3.2:latest\",\"model\":\"llama3.2:latest\",\"modified_at\":\"2026-01-07T17:48:35.1496098+01:00\",\"size\":2019393189,\"digest\":\"a80c4f17acd55265feec403c7aef86be0c25983ab279d83f3bcd3abbcb5b8b72\",\"details\":{\"parent_model\":\"\",\"format\":\"gguf\",\"family\":\"llama\",\"families\":[\"llama\"],\"parameter_size\":\"3.2B\",\"quantization_level\":\"Q4_K_M\"}}]}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests, json\n",
    "\n",
    "BASE = \"http://127.0.0.1:11434\"  # usa 127.0.0.1 para evitar rarezas con localhost en Windows\n",
    "\n",
    "def hit(method, path, payload=None, timeout=15):\n",
    "    url = f\"{BASE}{path}\"\n",
    "    try:\n",
    "        r = requests.request(method, url, json=payload, timeout=timeout)\n",
    "        ct = r.headers.get(\"content-type\", \"\")\n",
    "        text = r.text[:500]\n",
    "        print(f\"{method} {path} -> {r.status_code} | {ct}\")\n",
    "        if text:\n",
    "            print(text)\n",
    "        print(\"-\"*80)\n",
    "        return r\n",
    "    except Exception as e:\n",
    "        print(f\"{method} {path} -> EXCEPTION: {e}\")\n",
    "        print(\"-\"*80)\n",
    "        return None\n",
    "\n",
    "# 1) Nativo\n",
    "hit(\"GET\", \"/api/version\")\n",
    "hit(\"GET\", \"/api/tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ad18ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['llama3.2:latest']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "BASE = \"http://127.0.0.1:11434\"\n",
    "\n",
    "r = requests.get(f\"{BASE}/v1/models\", timeout=30)\n",
    "r.raise_for_status()\n",
    "\n",
    "models = [m[\"id\"] for m in r.json().get(\"data\", [])]\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4a37aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: llama3.2:latest\n",
      "Existen varios frameworks para gestionar flujos de agentes, que se enfocan en la modelización y el análisis de sistemas complejos. A continuación, te menciono algunos de los más destacados:\n",
      "\n",
      "1. **Framework de Flujos de Agentes (AFL)**: Desarrollado por el Instituto Nacional de Investigación en Ciencias Aplicadas y Tecnología Industrial (INCIPI), este framework se enfoca en la modelización de sistemas complejos utilizando flujos de agentes.\n",
      "2. **Framework de Modelado de Flujos de Agentes (MFSA)**: Propuesto por la Universidad Politécnica de Madrid, este framework utiliza técnicas de modelado para analizar y simular sistemas complejos que involucran flujos de agentes.\n",
      "3. **Framework de Análisis de Flujos de Agentes (AFS)**: Desarrollado por el Instituto de Investigación en Sistemas Complejos (IISC), este framework se enfoca en la análisis y la evaluación de sistemas complejos que involucran flujos de agentes.\n",
      "4. **Framework de Modelado de Redes de Agentes (MRA)**: Propuesto por la Universidad de California, Irvine, este framework utiliza técnicas de modelado para analizar y simular sistemas complejos que involucran redes de agentes.\n",
      "\n",
      "Otros frameworks notables incluyen:\n",
      "\n",
      "* **Framework de Flujos de Procesos (BPM)**: Se enfoca en la modelización de procesos empresariales y no es específicamente un framework de flujos de agentes.\n",
      "* **Framework de Modelado de Sistemas Complejos (MSCM)**: Propuesto por la Universidad de Oxford, se enfoca en la modelización de sistemas complejos utilizando técnicas de análisis de redes y flujos de procesos.\n",
      "* **Framework de Análisis de Flujos de Redes (AFR)**: Desarrollado por el Instituto de Investigación en Sistemas Complejos (IISC), se enfoca en la análisis y la evaluación de sistemas complejos que involucran redes de agentes.\n",
      "\n",
      "Es importante destacar que estos frameworks pueden tener objetivos y enfoques diferentes, y no todos están específicamente diseñados para gestionar flujos agénticos.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "BASE = \"http://127.0.0.1:11434\"\n",
    "MODEL = models[0]\n",
    "\n",
    "payload = {\n",
    "    \"model\": MODEL,\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"Responde en español, técnico y conciso.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Qué frameworks existen actuamente para gestionar flujos agénticos? (cita almenos 4)\"}\n",
    "    ],\n",
    "    \"temperature\": 0.2,\n",
    "    \"stream\": False\n",
    "}\n",
    "\n",
    "r = requests.post(f\"{BASE}/v1/chat/completions\", json=payload, timeout=120)\n",
    "r.raise_for_status()\n",
    "\n",
    "j = r.json()\n",
    "print(\"MODEL:\", MODEL)\n",
    "print(j[\"choices\"][0][\"message\"][\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c655586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moondream | writing manifest     | {'status': 'writing manifest'}\n",
      "Descarga finalizada.\n"
     ]
    }
   ],
   "source": [
    "# Modelo de visión:\n",
    "pull_model(\"moondream\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a60ae2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ADS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
